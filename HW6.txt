Michael Quinn

1. Page 167 exercise 3.1:
Indicate the binding time (when the language is designed, when the program is linked, when the program begins execution, etc.) for each of the following decisions in your favorite programming language and implementation. Explain any answers you think are open to interpretation.

Let's go with C++ for this.

a) The number of built-in functions (math, type queries, etc.)
Design Time; because they are built-in and not library functions, they are known immediately.

b) The variable declaration that corresponds to a particular variable reference (use)
Run Time; while they can be known before linking time, the binding itself does not occur until Run Time.

c) The maximum length allowed for a constant (literal) character string
Design Time; this value is known immediately as it is a literal, and not stored as a variable per-say.

d) The referencing environment for a subroutine that is passed as a parameter
Run Time; again, it may be inferred earlier, but it is not actually bound until it is run.

e) The address of a particular library routine
Link Time; if it's in a library it has to be linked first, but it is known before the program begins running.

f) The total amount of space occupied by program code and data
Link Time; technically it happens after everything is linked, but it still is reserved before execution begins.


2 and 3: Unfortunately, no instructions are given on how to run powR.c, and it will not run because it has no entry point.

4. Many storage-management algorithms maintain a list of free blocks.  Here are two different algorithms, first fit and best fit, used to search this list and return a block of the appropriate size.  Which strategy, if either, will result in lower external fragmentation?  What does external fragmentation depend on?
First Fit will use the first free block that is large enough to store the block, while Best Fit searches for the smallest block that is large enough. Best Fit is very good at preventing Internal Fragmentation, but can lead to more External Fragmentation in some cases. External Fragmentation is best described by the number of blocks that the free space is divided into; because First Fit tends to cluster more blocks towards the beginning, and is more likely to make use of the Free Blocks between used blocks, it often results in lower external fragmentation. 
That said, the external fragmentation really depends on the size distribution of the blocks; if there are many larger blocks, Best Fit will likely result in lower External Fragmentation, while First Fit may be better when there are many smaller blocks.

5. First Fit has a complexity of O(N), as it sweeps the block list from start until it finds one that fits. There is generally not a viable method to improve its speed, as the size distribution of blocks in the heap are fairly arbitrary, so the layout of the data structure cannot be exploited to improve speed.
The best possible method to improve First Fit would then be to reorder the heap from smallest block to largest block. Such an algorithm would effectively be a sorting algorithm, but based on the memory size rather than data values; seeing as the fastest sorting algorithm, QuickSort, has an average complexity of O(nlgn), this would increase the compelxity of First Fit to O(nlgn) for most cases, with a worst case of O(n^2).

6. What is garbage? How is it created, and why is it a problem? Discuss the
comparative advantages of reference counts and tracing collection as a means
of solving the problem.
Garbage is data stored in memory that is no longer usable; when all references to it have been overwritten or deleted, but the data itself is still taking up memory.
Garbage is created when data is stored in the heap, referenced by a pointer of some sort, then all references to it are removed. Garbage is a significant problem in C and C++ as these languages do not have native garbage collectors, and rely on the programmer to manually remove the garbage themselves. Garbage causes problems because it accumulates, taking up more and more memory as more is gathered until there is no longer enough free space to run the program, at which point it crashes; prior to crashing, the program will slow down as the additional garbage makes memory fragmentation more significant of a problem as the computer has fewer and fewer free blocks to work with.
Reference Counts are a simple way to manage garbage; the computer tracks the number of references to an object, increasing it whenever a reference is created and decreasing it whenever one is destroyed: when the reference count for an object drops to 0, the object is then deleted from memory as it is now garbage.
That said, it can be difficult for a program to determine how many references an object has, due to how data is stored; it must be able to rely on the compiler to tell what parts of memory are pointers. For languages that allow undeclared types, this doesn't work.
With Tracing Collection, the computer navigates the heap starting from external pointers, but first marks everything as "garbage;" whenever it reaches a memory block, it removes the "garbage" mark, and if it is a pointer, goes to where it is pointing and does the same. Once it's gone through every pointer, it removes any blocks that are still marked as garbage.
This is more thorough than Reference Counts, but requires blocks to either be of uniform size or to have headers announcing their size so the compiler can tell how big each block is; it also needs to be able to tell what is a pointer and what isn't a pointer.

Effectively, Reference Counts are "better" when you don't need to be super thorough and/or if the memory blocks are of differing sizes, while Tracing Collection is "better" if thoroughness is important.